<https://www.bilibili.com/video/av52353696?p=7>

# 分层架构

## jvm层

    1、single JVM。
    2、cluster yarn。
    3、cloud ec2

## 运行时层

    分布式流系统

## 高级API层

    1、DataStream API
    2、DataSet API

## 应用

### DataStream API

    1、CEP复杂事件处理。
    2、table API & SQL API

### DataSet API

    1、FlinkML
    2、Gelly
    3、table api & SQL API

# API四层分层

    1、SQL。顶层。
    2、Table API。declarative dsl语言
    3、DataStream API/DataSet API coreAPIs核心api
    4、Stateful Stream Processing 底层api

## Stateful Stream Processing

    1、最底层的api接口，复杂灵活
    ref：https://ci.apache.org/projects/flink/flink-docs-stable/dev/stream/operators/process_function.html
    2、stream.keyBy(...).process(new MyProcessFunction()) 继承KeyedProcessFunction

## Core API

    1、DataSet —— 批处理API
    2、DataStream —— 流处理API

## Table API & SQL

    1、sql构建在table上，都需要构建table环境。
    2、不同的类型的table构建不同的table环境。
    3、table可以与DataStream或DataSet进行相互转换。
    4、Streaming SQL不同于存储的SQL，最终会转换为流式执行计划。

# flink dataflow

## Flink Dataflow的基本套路

    这部分要注意到flink的两个重点优势：
    1、分布式流处理，也就是DataStream是在多台机器上的。
    2、多流join,相比与nifi,flink是支持多数据源的join

    flink的数据
    0、环境准备：构建计算环境
    1、输入：创建DataSource，比如kafka消费。
    2、处理：不同算子（keyby,group等等）
    3、输出：sink。比如写到kafka。

### 编码示例

```
// 1、创建数据源
DataStream<String> lines = env.addSource(
    new FlinkKafkaConsumer<> (...)
);
// 2、处理
DataStream<Event> events = lines.map((line)->parse(line));
// 3、处理
DataStream<Statistics> stats = events
    .keyBy("id")
    .timeWindow(Time.seconds(10))
    .apply(new MyWindowAggregationFunction());
// 4、sink
stats.addSink(new RollingSink(path));
```

### 并行化DataFlow

    增加并行度，parallelism,通过两个source的并行消费kafka的数据，然后并行本地map数据，再进行shuffle，通过keyby(),window()进行重新洗牌。

### One-to-one Streams

### Redistribute Stream

    1、keyBy()
    2、broadcast()
    3、reblance()
